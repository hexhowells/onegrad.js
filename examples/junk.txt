var onegrad = require("./../onegrad/tensor.js")
var nj = require("numjs");

var w = new onegrad.randn([3, 1]);
var temp = new onegrad.Tensor([[1.9], [0.5], [0.0]])
w = w.sub(temp)
//var b = new onegrad.randn([1, 1]);
const epochs = 50;

//var inputs = [[0,0,0], [0,0,1], [0,1,0], [0,1,1], [1,0,0], [1,0,1], [1,1,0], [1,1,1]];
//var inputs = [[0,0,1], [1,1,1], [1,0,1], [0,1,1]]
//var targets = [0, 0, 0, 0, 0, 0, 0, 1];
//var targets = [0, 1, 1, 0]

var inputs = [[1,0,0], [0,0,1]]
var targets = [0, 1]

function optim(params) {
	for (param of params){
		var update = nj.multiply(param.grad, 0.1)
		//console.log("optim - update: ", update.tolist())
		//console.log("optim - cur param: ", param.selection.tolist())
		param.selection = nj.add(param.selection, update)
		//console.log("optim - new param: ", param.selection.tolist())
	}
}


for (let epoch=0; epoch<epochs; epoch++){
	console.log(`\n\n\nEpoch ${epoch+1} of ${epochs}`)
	for (let i=0; i<inputs.length; i++){
		var input_tensor = new onegrad.Tensor([inputs[i]]);
		var target_tensor = new onegrad.Tensor([[targets[i]]]);
		
		//console.log("\ninput_tensor: ", input_tensor.tolist())
		//console.log("target_tensor: ", target_tensor.tolist())

		var output = input_tensor.dot(w)
		output = onegrad.sigmoid(output)
		var loss = target_tensor.sub(output)
		
		console.log("out: ", output.tolist())
		console.log("weights: ", w.selection.tolist())
		//console.log("loss: ", loss.tolist())
		loss.zeroGrad()
		loss.backward()
		optim([w])
	}
	
	console.log("weights: ", w.selection.tolist())

}